{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c282a6",
   "metadata": {},
   "source": [
    "# Audio Features\n",
    "\n",
    "Audio features are compact, meaningful measurements extracted from short speech frames that make learning easier.  \n",
    "\n",
    "Intuitively:  \n",
    "“What properties of this sound matter for my task?”  \n",
    "some examples:  \n",
    "\n",
    "| Task       | What matters              |\n",
    "| ---------- | ------------------------- |\n",
    "| Speaker ID | Vocal tract shape, timbre |\n",
    "| Emotion    | Pitch, energy, rhythm     |\n",
    "| Health     | Voice stability, noise    |\n",
    "| Age/Gender | Pitch range, formants     |\n",
    "\n",
    "# Time domain features (No FFT)\n",
    "\n",
    "as we have seen earlier that FFT(fast fourier transform) is used to convert time domain data to frequency domain.  \n",
    "\n",
    "## Energy (Loudness)\n",
    "\n",
    "What:  \n",
    "How strong the signal is in the frame.  \n",
    "\n",
    "Intuition:  \n",
    "Loud vs quiet speech.  \n",
    "\n",
    "Used for:\n",
    "- Voice activity detection (speech vs silence)\n",
    "- Emotion (anger vs calm)\n",
    "- Stress detection\n",
    "\n",
    "## Zero Crossing Rate (ZCR)\n",
    "\n",
    "What:  \n",
    "How often the waveform crosses zero.  \n",
    "\n",
    "Intuition:\n",
    "- Noisy sounds → high ZCR\n",
    "- Voiced sounds → low ZCR\n",
    "\n",
    "Used for:\n",
    "- Voiced vs unvoiced detection\n",
    "- Rough speech characterization\n",
    "\n",
    "Rarely used alone in modern systems.  \n",
    "\n",
    "# Frequency domain and spectral features(after FFT)\n",
    "\n",
    "## Spectral Centroid\n",
    "\n",
    "What:  \n",
    "“Center of mass” of frequencies.\n",
    "\n",
    "Intuition:  \n",
    "- Low centroid → dark / deep voice\n",
    "- High centroid → bright / sharp sound\n",
    "\n",
    "Used for:\n",
    "- Emotion\n",
    "- Timbre analysis\n",
    "\n",
    "## Spectral Bandwidth, Roll-off, Flux\n",
    "\n",
    "| Feature   | Intuition                  |\n",
    "| --------- | -------------------------- |\n",
    "| Bandwidth | How spread frequencies are |\n",
    "| Roll-off  | High-frequency cutoff      |\n",
    "| Flux      | How fast spectrum changes  |\n",
    "\n",
    "These are common in music/audio, less dominant in speech ML today.\n",
    "\n",
    "## Cepstral Features — MFCCs (Very Important)\n",
    "\n",
    "To understand the Cepstrum, think about how you speak:\n",
    "\n",
    "- The Source (Vocal Cords): Your vocal cords vibrate at a certain speed. This creates the pitch of your voice.\n",
    "- The Filter (Vocal Tract): Your mouth and tongue change shape to turn those vibrations into specific sounds like \"Ah\" or \"Ee.\" This is the timbre or \"texture\" of the sound.\n",
    "\n",
    "When you record a sound, the Source and Filter are \"tangled\" together. The Spectrum shows them as one messy line. The Cepstrum is the mathematical tool that reaches in and pulls them apart so you can analyze the pitch and the texture separately.\n",
    "\n",
    "- Quenfrency - domain of the spectrum. Measures the rate of change in the log spectrum.\n",
    "- Cepstrum is a wordpay on spectrum i.e. it is another spectrogram\n",
    "- same for quenfrency, it is an anagram of frequency\n",
    "\n",
    "### Why MFCCs Exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20659b4d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
