{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c282a6",
   "metadata": {},
   "source": [
    "# Audio Features\n",
    "\n",
    "Audio features are compact, meaningful measurements extracted from short speech frames that make learning easier.  \n",
    "\n",
    "Intuitively:  \n",
    "“What properties of this sound matter for my task?”  \n",
    "some examples:  \n",
    "\n",
    "| Task       | What matters              |\n",
    "| ---------- | ------------------------- |\n",
    "| Speaker ID | Vocal tract shape, timbre |\n",
    "| Emotion    | Pitch, energy, rhythm     |\n",
    "| Health     | Voice stability, noise    |\n",
    "| Age/Gender | Pitch range, formants     |\n",
    "\n",
    "# Time domain features (No FFT)\n",
    "\n",
    "as we have seen earlier that FFT(fast fourier transform) is used to convert time domain data to frequency domain.  \n",
    "\n",
    "## Energy (Loudness)\n",
    "\n",
    "What:  \n",
    "How strong the signal is in the frame.  \n",
    "\n",
    "Intuition:  \n",
    "Loud vs quiet speech.  \n",
    "\n",
    "Used for:\n",
    "- Voice activity detection (speech vs silence)\n",
    "- Emotion (anger vs calm)\n",
    "- Stress detection\n",
    "\n",
    "## Zero Crossing Rate (ZCR)\n",
    "\n",
    "What:  \n",
    "How often the waveform crosses zero.  \n",
    "\n",
    "Intuition:\n",
    "- Noisy sounds → high ZCR\n",
    "- Voiced sounds → low ZCR\n",
    "\n",
    "Used for:\n",
    "- Voiced vs unvoiced detection\n",
    "- Rough speech characterization\n",
    "\n",
    "Rarely used alone in modern systems.  \n",
    "\n",
    "# Frequency domain and spectral features(after FFT)\n",
    "\n",
    "## Spectral Centroid\n",
    "\n",
    "What:  \n",
    "“Center of mass” of frequencies.\n",
    "\n",
    "Intuition:  \n",
    "- Low centroid → dark / deep voice\n",
    "- High centroid → bright / sharp sound\n",
    "\n",
    "Used for:\n",
    "- Emotion\n",
    "- Timbre analysis\n",
    "\n",
    "## Spectral Bandwidth, Roll-off, Flux\n",
    "\n",
    "| Feature   | Intuition                  |\n",
    "| --------- | -------------------------- |\n",
    "| Bandwidth | How spread frequencies are |\n",
    "| Roll-off  | High-frequency cutoff      |\n",
    "| Flux      | How fast spectrum changes  |\n",
    "\n",
    "These are common in music/audio, less dominant in speech ML today.\n",
    "\n",
    "## Cepstral Features — MFCCs (Very Important)\n",
    "\n",
    "In speech processing and machine learning, Cepstral Features are the specific numbers (coefficients) extracted during Cepstrum analysis. They are essentially a \"summary\" of the sound's texture and characteristics.\n",
    "\n",
    "### The cepstrum\n",
    "\n",
    "To understand the Cepstrum, think about how you speak:\n",
    "\n",
    "- The Source (Vocal Cords): Your vocal cords vibrate at a certain speed. This creates the pitch of your voice.\n",
    "- The Filter (Vocal Tract): Your mouth and tongue change shape to turn those vibrations into specific sounds like \"Ah\" or \"Ee.\" This is the timbre or \"texture\" of the sound.\n",
    "\n",
    "When you record a sound, the Source and Filter are \"tangled\" together. The Spectrum shows them as one messy line. The Cepstrum is the mathematical tool that reaches in and pulls them apart so you can analyze the pitch and the texture separately.  \n",
    "\n",
    "In standard signal processing, the Fourier Transform (FFT) moves you from Time to Frequency. To get back, you use the Inverse Fourier Transform (IFFT).  \n",
    "\n",
    "In a Cepstrum, you do something unusual:\n",
    "1. Forward: You take the FFT (Time → Frequency).\n",
    "2. Processing: You take the Logarithm of that spectrum.\n",
    "3. \"Backwards\": You take the IFFT (Frequency → \"New Time\").\n",
    "\n",
    "Because you took the logarithm in the middle, the IFFT doesn't bring you back to the original sound wave. Instead, it lands you in a \"pseudo-time\" domain called Quefrency. It feels like you turned around and walked back toward the starting line, but ended up in a parallel dimension.  \n",
    "\n",
    "The scientists who created this (Tukey et al.) realized they were doing everything in reverse. To signal this to other engineers, they flipped the names of everything:\n",
    "- SPECtrum\t-> CEPStrum\n",
    "- FREQuency ->\tQUEFrency\n",
    "- FILTer -> LIFTer\n",
    "- PHASe -> SAPHe\n",
    "- HARMonic -> RAHMonic\n",
    "\n",
    "### Mel-Frequency Cepstral Coefficients\n",
    "\n",
    "The MFCC is actually a specific type of Cepstrum. The word \"Cepstral\" in MFCC tells you that it uses the same core \"backwards\" logic (taking the transform of a log-spectrum).\n",
    "\n",
    "The Pipeline Connection:\n",
    "- Cepstrum: Signal → FFT → Log → IFFT\n",
    "- MFCC: Signal → FFT → Mel-Filterbank → Log → DCT(descrete cosine transform - a variation of IFFT)\n",
    "\n",
    "#### Importance of the Mel Filterbank\n",
    "\n",
    "Humans are very good at telling the difference between 500 Hz and 600 Hz, but we are terrible at telling the difference between 10,000 Hz and 10,100 Hz, even though the gap (100 Hz) is the same.\n",
    "\n",
    "- The Cepstrum doesn't care about this; it analyzes everything linearly.\n",
    "- The MFCC \"warps\" the frequency axis using the Mel Scale to match our ears. This is why MFCCs are the \"gold standard\" for AI models that need to \"hear\" like people (e.g., Alexa, Siri).\n",
    "\n",
    "### Why MFCCs Exist\n",
    "\n",
    "Key problem:\n",
    "- Spectrum is too detailed\n",
    "- Humans care about spectral envelope, not fine harmonics\n",
    "\n",
    "MFCCs capture:\n",
    "- The shape of the vocal tract, not pitch harmonics\n",
    "\n",
    "### Intuition\n",
    "- Mel filters ≈ how humans hear frequency\n",
    "- Log ≈ loudness perception\n",
    "- DCT ≈ compression & decorrelation\n",
    "\n",
    "MFCCs ≈ compressed vocal tract signature\n",
    "\n",
    "### What MFCCs capture\n",
    "\n",
    "| Captures          | Ignores        |\n",
    "| ----------------- | -------------- |\n",
    "| Vocal tract shape | Exact pitch    |\n",
    "| Timbre            | Phase          |\n",
    "| Speaker identity  | Fine harmonics |\n",
    "\n",
    "- useful notebook - [mfcc tutorial](https://www.kaggle.com/code/ilyamich/mfcc-implementation-and-tutorial)\n",
    "- useful video - [mfcc explained](https://youtu.be/SJo7vPgRlBQ?si=PEnwwwayWV1Rstza)\n",
    "\n",
    "## Prosodic features\n",
    "\n",
    "Prosodic features are not concerned with what you said, they are concerned with how you said it.  \n",
    "we can roughly summarize prosody as : `Prosody = rhythm + intonation`  \n",
    "\n",
    "#### rhythm\n",
    "\n",
    "Rhythm is the timing and pattern of sounds. In English, we don't say every syllable with the same length or strength.  \n",
    "\n",
    "- Pacing: Speaking fast when excited or slow when explaining something complex.\n",
    "- Pauses: A pause can change the meaning of a sentence entirely.\n",
    "    - Example: \"Let’s eat, Grandma!\" vs. \"Let’s eat Grandma!\" (The pause—or comma—saves Grandma's life).\n",
    "\n",
    "- Stress: We \"punch\" certain syllables or words to make them stand out.\n",
    "\n",
    "    - Example: Say \"I didn't steal the money.\" Now say it again, but stress a different word each time (e.g., \"**I** didn't steal it\" vs \"I didn't **steal** it\"). The rhythm changes the accusation.\n",
    "\n",
    "#### Intonation\n",
    "\n",
    "Intonation is the \"rise and fall\" of your pitch. It tells the listener about your emotions and your intentions.\n",
    "\n",
    "- Rising Pitch: Usually signals a question or uncertainty. Your voice goes up at the end: \"You're coming tonight?\"\n",
    "- Falling Pitch: Usually signals a statement, a command, or finality: \"You're coming tonight.\"\n",
    "- Tone of Voice: This is how we detect sarcasm, anger, or joy. If you say \"Great job\" with a high, bouncy pitch, it’s a compliment. If you say it with a flat, low pitch, it's sarcasm.\n",
    "\n",
    "There are various prosodic features such as pitch, energy contours, speaking rate etc.\n",
    "\n",
    "## Voice Quality Features\n",
    "\n",
    "These relate to micro-irregularities in voice.\n",
    "\n",
    "- Jitter - Cycle-to-cycle pitch variation.\n",
    "- Shimmer - Cycle-to-cycle amplitude variation.\n",
    "- Harmonics to Noise Ratio(HNR) - How “clean” the voice is.\n",
    "\n",
    "In speech analysis, the \"cycle\" refers to one single glottal cycle—which is the process of your vocal folds opening and closing exactly one time.\n",
    "\n",
    "## Fature task mapping\n",
    "\n",
    "| Feature Type   | Best For          |\n",
    "| -------------- | ----------------- |\n",
    "| Energy, ZCR    | VAD, emotion      |\n",
    "| Spectral stats | Timbre            |\n",
    "| MFCCs          | Speaker traits    |\n",
    "| Pitch          | Emotion, gender   |\n",
    "| Jitter/Shimmer | Health            |\n",
    "| Embeddings     | Everything modern |\n",
    "\n",
    "\n",
    "Modern systems prefer learned embeddings\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
